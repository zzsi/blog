---

title: "Beyond Counsel: Why Citizens Deserve a Right to Sufficient AI Advisory"
date: "2025-07-20"
categories: \[AI Ethics, Law, Policy]
-------------------------------------

On a gray Tuesday, María Alvarez sat at her kitchen table, eyes ping‑ponging between a half‑finished coffee and a health‑insurance marketplace she barely understood. Forty‑nine and newly self‑employed, she was one misclick away from a plan that could swallow half her income—or leave her exposed when she needed care most. Deductibles hid behind links. “Coinsurance” sparred with “out‑of‑pocket maximum.” She guessed, picked the third‑cheapest plan, and prayed she had not made a year‑long mistake.

If María had been facing a criminal charge rather than an insurance portal, the Constitution would have met her at the threshold. The Sixth Amendment promises the assistance of counsel; in *Gideon v. Wainwright* (1963), the Supreme Court recognized that some kinds of expertise are so bound up with justice that government must help supply them. Later cases refined the idea into a standard of *effective* assistance rather than mere presence. The premise is simple and humane: a person cannot meaningfully defend their life or liberty without a guide through the thicket.

We now live much of our lives in a different thicket. Algorithms shape credit limits and college admissions; bureaucracies publish ever‑thickening rulebooks; contracts arrive in fonts small enough to dodge notice. The canyon between expert systems and everyday understanding widens by the month. The stage is no longer the courtroom but the portal, the form, the eligibility engine. The stakes are dispersed across days and domains, but they add up to the same thing: the terms on which people live.

This is why we should begin speaking, plainly and seriously, about a new civic guarantee: a **right to sufficient AI advisory**.

> If technology is a form of power, then access to the best advice it can synthesize is a form of freedom.

---

## The Counsel Analogy—And the Limits of the Metaphor

It is tempting to treat “AI advisory” as a digital public defender. The analogy clarifies more than it distorts, but it does have edges. Lawyers are licensed humans; they owe fiduciary duties to their clients and can stand in a courtroom to represent them. An advisory system, by contrast, is not representation. It is closer to a translator and a mapmaker: it explains the terrain, shows the paths that satisfy the rules, warns when a cliff approaches, and tells you which documents to carry. In criminal cases, the law protects liberty with counsel. In the administrative and commercial state, dignity requires something parallel: the means to participate *intelligently* in systems that govern health, housing, credit, schooling, and work.

American due‑process law already gestures in this direction. *Goldberg v. Kelly* (1970) recognized that public benefits can be as vital as wages, and that fair procedures must accompany their withdrawal. *Mathews v. Eldridge* (1976) taught that the level of procedural safeguard should scale with the stakes. Taken together, these cases read less like a closed chapter than like an invitation: when government or quasi‑governmental systems set the terms of ordinary life, people must be able to understand and contest those terms.

Today, the official answer—PDFs, call centers with long queues, and websites that politely obscure—is no longer up to the job. Private tools are plentiful, but their loyalties are negotiated in terms of service and advertising models rather than guaranteed in law. They are often helpful, but they are not counsel. They are sales.

---

## What “Sufficient” Should Mean

“Sufficient” is not a mood; it is a standard. A right to advisory would be hollow if it merely gestured toward chatty interfaces. The advisory must be able to *do work* on behalf of understanding. It should read the plan document and the regulation, not just summarize a blog post. It should say *why* Plan A is safer than Plan B, and on what legal or policy footing that judgment stands. It should admit uncertainty and show its confidence the way a careful expert does, with an explanation of what would change its mind.

Independence is part of sufficiency. An advisory system that is quietly paid to steer you toward a product is not a guide; it is a broker with a smile. Structural insulation from the entities being critiqued is essential—no undisclosed referral fees, no embedded upsells, no dangling of “premium” advice reserved for those who can pay. The system must feel, and be, on the citizen’s side.

Accessibility is not an afterthought. Free at the point of use, multilingual, friendly to older devices and low bandwidth, designed for people with limited digital literacy or disabilities—these are the conditions under which a right reaches everyone rather than a few. Privacy belongs in the same sentence: data should be siloed and encrypted, never sold or repurposed without informed consent, with privilege‑like limits on disclosure so that people can ask hard questions without fear of self‑incrimination by algorithm.

Fairness and recourse give the right teeth. Because errors will happen, the system should be built to notice and correct them. That means regular checks for uneven error rates across language groups or neighborhoods; it means visible pathways to challenge harmful advice; it means a human escalation channel when the model is unsure, when the user asks, or when the stakes are simply too high to automate. In a criminal courtroom, you do not face a life‑altering decision without a person beside you. In the digital state, eviction, benefit termination, or denial of medically necessary care ought to trigger the same reflex: bring a human in.

---

## Why Make It a Right?

We could leave all of this to the market—and in many places we have. But markets are excellent at producing tools for people who can pay and patient capital for problems that monetize well. They are less reliable as guardians of equity. A right articulates a floor beneath which we will not let one another fall. It says that we do not accept a future divided between the well‑advised and the algorithmically outmatched.

It also makes government more competent. The hidden costs of bad advice—avoidable denials, needless appeals, scandals that require years of reparations—far exceed the price of preventive guidance. Better first‑time decisions are cheaper for agencies and kinder to citizens. And because a public advisory service would see, in privacy‑preserving aggregate, where people stumble, legislators would gain a living map of confusing statutes and forms. Democratic feedback would stop being a metaphor and become a dataset.

Finally, making it a right forces transparency. Bias thrives in darkness. A recognized right would bring audits, explanations, and redress into the sunlight, replacing “trust us” with “show us.”

---

## A Glimpse of What Already Exists—and What’s Missing

Pieces of the future are visible. Estonia’s “Kratt” assistant helps residents navigate services in natural language. Spain’s *Carta de Derechos Digitales* points toward algorithmic transparency. The European Union’s AI Act classifies many public‑service systems as high‑risk and requires documentation, testing, and oversight. These are genuine achievements. Yet they mostly regulate providers rather than empower individuals with an entitlement to personalized, competent advice at the moment of decision.

Commercial systems inch closer—tax coaches, symptom checkers, comparison engines. Some are genuinely useful. But their loyalties remain private, their safeguards contractual, their scope determined by product strategy rather than public need. They are supplements; they are not substitutes for a public guarantee.

---

## How We Could Build It Without Breaking the World

The path forward need not be theatrical. Legislatures could begin by recognizing a right to advisory in a few high‑impact domains—healthcare, housing, education finance, and consumer credit—where the rules are dense and mistakes are expensive. Agencies could be required to publish the relevant rules in machine‑readable form so that advisory systems can cite and cross‑check rather than hallucinate; there is already a small canon of formats and projects—Akoma Ntoso for statutes, OpenFisca‑style rulesets for benefits—that show how to do this cleanly.

A public option would anchor the ecosystem: a government‑operated service with an open interface, free at the point of use, built to be measured. Around it, accredited nonprofits and firms could provide alternative front ends, provided they meet the same sufficiency standards and submit to the same audits. When confidence is low or stakes are high, the default shifts to human review, with service‑level guarantees that a person will call you back and help you finish the job.

Governance matters as much as code. An independent oversight body—something between an ombudsman and a public defender—should license advisory systems, investigate complaints, and revoke certification for repeated harms. Rather than reinvent rules from scratch, it can align with familiar scaffolding like NIST’s AI Risk Management Framework and the emerging family of AI governance standards, translating abstract principles into a short list of obligations: measure accuracy and calibration; publish sources; test for subgroup disparities; protect privacy; make it easy to appeal; and show that human escalation works.

Liability should be thoughtful rather than punitive. A limited safe harbor, conditioned on meeting the standards and responding to verified harms, would encourage investment while making room for learning. The goal is not to freeze the technology in amber, but to bind it to citizenship.

---

## A Global Frame

This conversation is not confined to Washington or Brussels. India’s Aadhaar‑linked services, Kenya’s digital IDs, Brazil’s open‑government data efforts—all of these initiatives push daily life onto screens and into workflows. The question they pose is quiet and universal: when citizenship is mediated by code, what guarantees shield the person? A right to sufficient AI advisory could travel across legal cultures the way freedom of expression did in the twentieth century, adapting to different institutions while keeping its heart the same.

---

## Objections Worth Hearing

Will people become dependent on AI? Of course some will. Many of us already rely on maps to drive across town. The point is not to displace judgment but to scaffold it—especially where the system’s rules are designed for machines to begin with. A good advisory system is a teacher that invites override, not an oracle that demands surrender.

Isn’t AI biased? Yes, and so are humans. The cure is not banishment but accountability. A recognized right would pull advisory systems into a regime of evidence: show your sources, measure your errors, disclose your gaps, and fix what you break.

Will this be expensive? Less than the status quo. Model training and retrieval over public rulebooks are inexpensive at scale; every avoided denial and shortened appeal is money saved and time returned. Human escalations should be reserved for the places where they matter most, which keeps the system humane without making it unaffordable.

Does this authorize the unauthorized practice of law or medicine? No. The right should be framed as educational, rights‑enabling assistance with statutory carve‑outs and mandatory escalation to licensed professionals when the subject matter or stakes require it. We already do this every day in triage and self‑help clinics. This would make the practice safer and more consistent.

---

## Canvas: The Policy on One Page

**Problem.** People make life‑shaping decisions inside systems built for specialists and machines. The gap between what the system knows and what the person can reasonably understand has become a justice problem.

**Principle.** Dignity in a digital state demands not only non‑discrimination and transparency, but also *guided participation*. The right is to advice that is competent, independent, accessible, private, fair—and that brings a human in when the stakes are high.

**Implementation.** Start with the domains where mistakes are expensive and common. Publish rules in machine‑readable form. Stand up a public option; license independent providers who meet the same standard. Measure accuracy, calibration, and disparities; require source citation; protect privacy by default. Create an oversight body with power to certify, investigate, and correct.

**Outcomes.** Fewer erroneous denials, faster and more accurate decisions, smaller disparities across language and income, and legislation that actually responds to where people struggle. In short: a state that is easier to live with.

---

## Closing: Choosing the Future We Inhabit

Near the end of *Gideon’s Trumpet*, Anthony Lewis suggests that the case mattered not because it freed one man, but because it proved a country could correct itself. Our machinery now is digital; the decisions are diffuse; the harms arrive not as headlines but as quiet losses. The principle endures. Power without accessible counter‑power breeds injustice. A right to sufficient AI advisory will not dissolve bureaucracy, but it will hand people the flashlight, the map, and the translator they increasingly need to move through modern life with agency.

María should not have to gamble her health on a hunch. Neither should you.

*References for curious readers: **Gideon v. Wainwright** (1963); **Strickland v. Washington** (1984); **Goldberg v. Kelly** (1970); **Mathews v. Eldridge** (1976); GDPR Art. 22; the EU AI Act (2024); Akoma Ntoso; OpenFisca; NIST AI Risk Management Framework.*

