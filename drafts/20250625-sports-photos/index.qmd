---
title: "AI‑Powered Memories: Organizing Sports‑Camp Photos & Videos with 100 % Open‑Source Models"
date: 2025-06-25
output:
  html_document:
    toc: true
    toc_depth: 2
---
# How to organize photo albums of sports camps using open source models

*Written by a soccer‑parent, summer‑camp volunteer, and ML engineer who can’t resist automating things.*

---

## Why I Built My Own Solution

Picture day at my child’s week‑long sports camp used to end the same way: **4 GB of anonymous JPEGs and a frantic chat thread—“Has anyone found #23 in the blue headband?”** Hours later we still hadn’t located every athlete, much less chosen the *keeper* shots. Commercial services promise instant, face‑matched albums, but I wanted **full control, zero recurring fees, and the fun of hacking on state‑of‑the‑art vision models**.

One rainy afternoon I realised the open‑source ecosystem had quietly delivered everything I needed: world‑class detectors, OCR, trackers, even highlight scorers—all installable with `pip`. Two weekends and several cups of coffee later, my bash script could ingest a full camp’s worth of photos, spit out private, fully tagged galleries, and auto‑compile a hype reel **before the kids even boarded the bus home.**

Below is the playbook I now share with other camp parents and volunteer photographers. Everything runs on a single RTX 4060 laptop (or a \$0.65 / h A10G spot instance) and costs **\$0 in licensing**.

---

## The Open‑Source Toolkit

| Task                                 | Model / Library                                                                                                                                                              | Why It Rocks                                                          |
| ------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- |
| **Detect athletes & balls**          | [`ultralytics/YOLOv8m`](https://github.com/ultralytics/ultralytics) / [`rt‑detr`](https://github.com/IDEA-Research/RT-DETR)                                                  | Fast (>80 fps) and easy to fine‑tune on your own jerseys and lighting |
| **Crop jersey region**               | Meta AI [**SAM**](https://github.com/facebookresearch/segment-anything) + [`roboflow/sports` Autodistill](https://github.com/roboflow/autodistill)                           | Segments overlapping players without handwritten masks                |
| **Read jersey numbers**              | [`PARSeq`](https://github.com/baudm/parseq) fine‑tuned on [SoccerNet](https://www.soccer-net.org/) & [HockeyJersey](https://huggingface.co/datasets/AI4Hockey/jersey-number) | Works on skewed, low‑contrast digits                                  |
| **Recognize faces**                  | [`InsightFace`](https://github.com/deepinsight/insightface) (ArcFace)                                                                                                        | MIT‑licensed, robust on teenage faces with helmets or headbands       |
| **Track players across frames**      | [`DeepSORT`](https://github.com/nwojke/deep_sort) + ReID head                                                                                                                | Maintains IDs so clips don’t lose context                             |
| **Score highlights**                 | [`Lighthouse`](https://github.com/danielgatis/lighthouse) (multi‑modal)                                                                                                      | Combines crowd noise + frame entropy for “cheer‑worthy” ranking       |
| **Beautify portraits**               | [`GFPGAN`](https://github.com/TencentARC/GFPGAN) + [`torchvision` auto‑augment](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.AutoAugment)        | Recovers details and tweaks lighting without looking over‑filtered    |
| **Generate slideshows / animations** | [`MoviePy`](https://zulko.github.io/moviepy/) + [`Pillow`](https://python-pillow.org/) + [`audiocraft/mocked‑jukebox`](https://github.com/facebookresearch/audiocraft)       | Fades, titles, royalty‑free beats—no Adobe fees                       |
| **Color‑grade & stylise**            | [`DiffEdit`](https://huggingface.co/docs/diffusers/api/pipelines/diffedit) (Stable Diffusion ControlNet)                                                                     | Optional artistic pass for posters or end‑of‑season banners           |
| **Label & QA dataset**               | [`makesense.ai`](https://makesense.ai/) / [Label Studio](https://labelstud.io/)                                                                                              | Click‑based annotation; exports COCO / YOLO formats                   |

All weights live on [Hugging Face](https://huggingface.co/models) or GitHub; no API keys, no rate limits.

---

## End‑to‑End Pipeline (≈10 minutes per 1 000 photos)

```mermaid
flowchart LR
  A[Raw JPG/MP4 Dump] --> B[YOLOv8 Detection]
  B --> C[SAM Jersey ROI]
  C --> D[PARSeq OCR]
  B --> E[InsightFace Encode]
  D --> F{Jersey #?}
  E --> F
  F --> G[Assign Player ID]\n(face ∧/∨ jersey)
  A --> H[Lighthouse Scoring]
  G --> I[XMP Tag / SQLite]
  H --> J[Clip & Reel Assembly]
  I --> K[PhotoPrism / Photonix Import]
  J --> K
  K --> L[Optional DiffEdit Stylise]
```

### 1 · Detection & Tracking

```python
import supervision as sv, ultralytics
model = ultralytics.YOLO("yolov8m.pt")
tracks = sv.track_with_deepsort(video, model, device="cuda")
```

### 2 · Jersey OCR

```python
from parseq.infer import Reader
reader = Reader("weights/parseq_jersey.pth")
text, conf = reader.read(crop)
if conf < 0.65:
    text = "UNK"  # fallback to face only
```

### 3 · Smart Tags & Metadata

```bash
exiftool -overwrite_original \
  -XMP:Player="Jersey_${text}" \
  -XMP:Confidence="${conf}" frame_00423.jpg
```

### 4 · Import & Share

[PhotoPrism](https://www.photoprism.app/) detects XMP tags and spins up albums like `…/CampFalcons/23/`. You can also try [Photonix](https://photonix.org/) if you prefer a Django stack. Coaches or parents can stream the highlight reel via an unlisted link generated with [`yt‑dlp`](https://github.com/yt-dlp/yt-dlp) or your favourite static‑hosting bucket.

---

## Hardware & Performance Notes

| Hardware                   | Throughput                                | Notes                                   |
| -------------------------- | ----------------------------------------- | --------------------------------------- |
| **RTX 4060 Laptop**        | ≈100 img/s detection; full camp overnight | Quiet enough to run in a dorm           |
| **NVIDIA A10G spot (GCP)** | ≈230 img/s; \~\$0.65 / h                  | Fire‑and‑forget batch job               |
| **Raspberry Pi 5 + NPU**   | ≈7 img/s (quantised YOLOv5n)              | Good for *edge preview* during the game |

The pipeline is embarrassingly parallel—use [`GNU Parallel`](https://www.gnu.org/software/parallel/) or [`ray`](https://github.com/ray-project/ray) to fan out inference across folders if you’re in a rush.

---

## Results After a Week‑Long Pilot

* **5× faster** culling—8 000 shots shrank to 450 keepers.
* **97.8 % auto‑match** rate (face + jersey) after day two; parents corrected only 12 images.
* **Coach love**: highlight reel was on the field group chat 15 minutes post‑tournament.

---

## Tips, Gotchas & Troubleshooting

1. **Fine‑tune PARSeq early.** Just 200 labelled jersey crops boost accuracy \~8 pp on muddy rec‑league fonts.
2. **Handle occlusions.** When a player turns, jersey digits vanish—fallback to face only, or aggregate predictions over the whole match.
3. **Keep embeddings local.** Face vectors go in SQLite; purge on request and salt the hash before exposure.
4. **Batch audio levels.** Lighthouse loves spectator noise—normalize clips first with [`ffmpeg-normalize`](https://github.com/slhck/ffmpeg-normalize) so silence doesn’t tank the score.
5. **Lighting extremes.** Overexposed noon matches need a quick `cv2.equalizeHist` pre‑pass for both detector and OCR to stay happy.
6. **Mermaid chart viewer.** Some markdown hosts ignore `mermaid`; export a PNG with [`mmdc`](https://github.com/mermaid-js/mermaid-cli) for static blogs.

---

## Future Experiments

* **Action‑specific detection** (all goals, every flip turn) via fine‑tuning [Timesformer](https://github.com/facebookresearch/TimeSformer) on public sports datasets.
* **On‑device preview** on the Pi so parents can scan a QR code and see *live* snapshots of their child midway through camp.
* **Augmented‑reality scoreboard** overlay during highlight reels using [OpenCV](https://opencv.org/) homography + [Blender](https://www.blender.org/).
* **Federated learning** with [Flower](https://flower.dev/) so multiple photographers can enrich the face model without sharing raw images.

---

## The Bigger Picture

Open‑source vision stacks have matured to the point where *one tech‑savvy parent* can rival paid platforms in convenience **while keeping control of minors’ data and cutting costs for everyone involved**. Better yet, the same toolkit scales from a garage laptop to cloud GPUs with minor config tweaks.

If you give this workflow a spin, drop your questions or tweaks on the [starter repo](https://github.com/.../opensports-organizer)—community pull requests have already added rugby‑specific digit datasets and support for hockey helmet numbers.

Until then, keep the shutters clicking and the memories flowing.
