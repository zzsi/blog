<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-07-12">

<title>Agentic Causal Inference – Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About this blog</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/zzsi"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/zhangzhangsi/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Agentic Causal Inference</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">ai</div>
                <div class="quarto-category">llm</div>
                <div class="quarto-category">agentic</div>
                <div class="quarto-category">causal inference</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 12, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<!--
  TODO: add illustrations and visualizaitons for overall architecture, and challenges.
-->
<section id="backdrop-machine-age-of-sciences" class="level2">
<h2 class="anchored" data-anchor-id="backdrop-machine-age-of-sciences">Backdrop: Machine Age of Sciences</h2>
<p>Historians may one day mark the 2020s as the dawn of the machine age of sciences. Language models now draft proofs and experimental protocols; diffusion models fold proteins and sketch molecules before a chemist even picks up a pipette. Yet prediction is only half the story; scientists and businesses still need to answer the deeper question: <strong>why</strong>.</p>
<p>The plural on sciences is intentional. I want to emphasize the range of disciplines: physics, chemistry, biology, economics, sociology, computer science, data science, you name it. But in this post I would like to dedicate attention on causal inference.</p>
</section>
<section id="causal-inference-and-llms" class="level2">
<h2 class="anchored" data-anchor-id="causal-inference-and-llms">Causal Inference and LLMs</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="diagram_causal_agent.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="360"></p>
</figure>
</div>
<p>Causal inference is such an important decision making tool in life and in business. However, to be an expert in this field takes years of mathematical and statistical training. LLMs on the other hand are easy to use, but they lack rigor when reasoning about causality.</p>
<p>Integrating causality into LLM agents addresses limitations on both sides:</p>
<ul>
<li><strong>Pure causal methods</strong> demand strict assumptions and expert guidance.</li>
<li><strong>LLMs</strong> overflow with knowledge yet often mistake correlation for causation.</li>
</ul>
<p>By wiring LLM‑based agents to specialized causal inference libraries, we can automate the causal workflow: <strong>discovery -&gt; identification -&gt; estimation -&gt; refutation</strong>. The result is a new class of general‑purpose causal AI systems that parse tabular, time-series, and even multimodal data with human-like intuition and mathematical rigor.</p>
<p>Practically, that means the agent:</p>
<ol type="1">
<li><p><strong>Thinks</strong> (via an LLM) about what causal graph should link your variables</p></li>
<li><p><strong>Acts</strong> by writing Python: drawing DAGs, running ID algorithms, calling estimators, using libraries like <code>dowhy</code>, <code>econml</code>, <code>causaltune</code>, etc.</p></li>
<li><p><strong>Reflects</strong> on the results, prompting itself with “Do my assumptions still hold?”</p></li>
<li><p><strong>Iterates</strong> until a relevant answer surfaces, or it asks you for help.</p></li>
</ol>
<p>If that sounds suspiciously like a data scientist teamate with infinite patience, you’ve got the gist.</p>
<section id="lines-of-code-for-your-first-causal-inference-agent" class="level4">
<h4 class="anchored" data-anchor-id="lines-of-code-for-your-first-causal-inference-agent">10 lines of code for your first causal inference agent</h4>
<p>To illustrate the idea, here is a minimal snippet to estimate the effect of a new coupon on revenue. This may actually be sufficient to get you a quick answer, if (a big if) the data is ready.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.agents <span class="im">import</span> initialize_agent, Tool</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.llms <span class="im">import</span> OpenAI</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dowhy <span class="im">import</span> CausalModel</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> causaltune <span class="im">import</span> AutoTune</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> estimate_ate(df, treatment, outcome):</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> CausalModel(data<span class="op">=</span>df, treatment<span class="op">=</span>treatment, outcome<span class="op">=</span>outcome)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    ided <span class="op">=</span> model.identify_effect()</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    best <span class="op">=</span> AutoTune(model, df).best_estimator_</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model.estimate_effect(ided, method_name<span class="op">=</span>best)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>agent <span class="op">=</span> initialize_agent(</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    llm<span class="op">=</span>OpenAI(model_name<span class="op">=</span><span class="st">"gpt-4o-mini"</span>),</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    tools<span class="op">=</span>[Tool.from_function(estimate_ate)],</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    agent_type<span class="op">=</span><span class="st">"openai-tools"</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>agent.run(<span class="st">"Estimate the uplift of coupon_v2 on weekly revenue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Time to look at some interesting papers and open source projects:</p>
<hr>
</section>
<section id="singleagent-autonomous-pipelines" class="level3">
<h3 class="anchored" data-anchor-id="singleagent-autonomous-pipelines">Single‑Agent Autonomous Pipelines</h3>
<p><a href="https://arxiv.org/pdf/2408.06849"><strong>Causal&nbsp;Agent</strong></a> framework&nbsp;(2024):</p>
<ol type="1">
<li>An LLM operates in a ReAct‑style loop with a suite of causal tools—e.g.&nbsp;<a href="https://github.com/py-why/causallearn"><strong>CausalLearn</strong></a> for graph discovery and <a href="https://github.com/microsoft/EconML"><strong>EconML</strong></a> for effect estimation.</li>
<li>Given a dataset and a query (e.g.&nbsp;“Effect of&nbsp;X on&nbsp;Y?”) the agent automatically:
<ul>
<li>explores variable correlations,</li>
<li>hypothesizes causal links,</li>
<li>proposes a causal graph,</li>
<li>computes the quantitative effect of&nbsp;X on&nbsp;Y.</li>
</ul></li>
<li>Each step is backed by library outputs that the LLM interprets before deciding its next move.</li>
</ol>
<p>The framework’s hierarchical breakdown (variable‑level, edge‑level, graph‑level, effect‑level) has produced expert‑level accuracy on a testing dataset with 1.3k questions, all while providing interpretable explanations.</p>
<ul>
<li><strong><a href="https://arxiv.org/abs/2504.13263">Causal-Copilot (2025)</a></strong>
<ul>
<li>The agent chains <strong>20 + causal tools</strong>, from discovery to hyper-parameter tuning, inside a single LLM loop.<br>
</li>
<li>Works on both tabular and time-series data: prompts the user for a question, auto-selects the right discovery algorithm (e.g., NOTEARS, PC), tunes an estimator (DoubleML, CausalForest, IV), runs refuters, and returns an English report with effect size + CI.</li>
<li>Achieves state-of-the-art graph accuracy and effect-estimation error across five public benchmarks, edging out both classic SCD baselines and earlier LLM agents.</li>
</ul></li>
</ul>
</section>
<section id="debating-multiagent-systems-for-causal-discovery" class="level3">
<h3 class="anchored" data-anchor-id="debating-multiagent-systems-for-causal-discovery">Debating Multi‑Agent Systems for Causal Discovery</h3>
<p>Single agents sometimes hallucinate; multi‑agent approaches aim to reduce errors through <strong>debate and consensus</strong>.</p>
<ul>
<li><a href="https://arxiv.org/abs/2407.15073"><strong>Multi‑Agent Causal Discovery Using LLMs</strong></a>&nbsp;(2024) assigns dedicated LLM roles:
<ul>
<li><em>Affirmative Debaters</em> proposes a DAG using temporal cues and domain priors.</li>
<li><em>Negative Debaters</em> attacks the proposal by surfacing hidden confounders, incorrect temporal orderings, or omitted variables.</li>
<li><em>Judges</em> evaluate arguments and pick the most plausible structure.</li>
<li><em>Coders</em> materializes the agreed-upon algorithm, reruns it on the entire dataset, and emits the refined graph.</li>
</ul></li>
</ul>
<p>Experiments show these debating agents outperform both classical algorithms and single‑LLM prompts on datasets like <a href="https://www.kaggle.com/datasets/uciml/autompg-dataset">Auto MPG</a>, demonstrating that multiple specialized minds can yield more reliable causal graphs.</p>
<ul>
<li><strong><a href="https://arxiv.org/abs/2505.10936">Chain-of-Collaboration Prompting (2025)</a></strong> shows that giving sub-agents explicit roles (planner, verifier, critic) and letting them share scratch pads improves causal reasoning accuracy on CLADDER and Causal-Copilot QA tasks, cutting hallucinated edges by 35 % vs.&nbsp;single-prompt ReAct.</li>
</ul>
</section>
<section id="toolbox-layer-automl-nocode-platforms" class="level3">
<h3 class="anchored" data-anchor-id="toolbox-layer-automl-nocode-platforms">Toolbox Layer (AutoML &amp; No‑Code Platforms)</h3>
<p>Parallel to LLM research, we also see <strong>AutoML‑style causal platforms</strong> that automate model selection, tuning, and robustness checks.</p>
<ul>
<li><strong>AutoCausality</strong>: part of the <a href="https://www.pywhy.org/"><strong>PyWhy</strong></a> ecosystem, using hyper‑parameter search and ensembling to choose the best estimator for a dataset.</li>
<li><a href="https://www.amazon.science/publications/opportunityfinder-a-framework-for-automated-causal-inference"><strong>OpportunityFinder</strong></a>&nbsp;(Amazon&nbsp;2023) offers code‑less causal studies for panel data cleaning, cohorting, and computing effects (plus sensitivity) end‑to‑end.</li>
<li><a href="https://opensource.salesforce.com/causalai/latest/index.html"><strong>Salesforce CausalAI Library</strong></a> consolidates discovery and inference methods, synthetic data generators, and a no‑code GUI, scaling to larger problems via optimized multiprocessing.</li>
</ul>
<p>These toolkits enrich agentic workflows: an LLM planner can mix‑and‑match discovery, estimation, and AutoML selection modules without human intervention.</p>
<hr>
</section>
</section>
<section id="evaluating-causal-inference-agents" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-causal-inference-agents">Evaluating Causal Inference Agents</h2>
<p>How well do these causal inference agents perform? Here are some real or synthetic datasets and benchmarks.</p>
<p>For treatment‑effect estimation, the <em><a href="https://bcallaway11.github.io/qte/reference/lalonde.html">Lalonde job‑training study</a></em> is a good place to start. It has real observational covariates paired with true RCT outcomes—to sanity‑check bias reduction. When larger, controlled replications are needed, you can use semi‑synthetic generators such as <em><a href="https://paperswithcode.com/dataset/ihdp">IHDP</a></em> and the <em><a href="https://www.pywhy.org/dowhy/v0.12/example_notebooks/dowhy_twins_example.html">Twins dataset</a></em>, whose perfect counterfactual comes from each twin’s paired outcome. The annual <em><a href="https://acic2022.mathematica.org/">ACIC challenges</a></em> extend this idea with dozens of high‑dimensional scenarios, while the 2025 <em><a href="https://openreview.net/forum?id=m28E5RN64hi">RealCause generator</a></em> allows people to create realistic Lalonde‑style benchmarks.</p>
<p>For longitudinal uplift studies, Amazon’s no‑code <em><a href="https://www.amazon.science/publications/opportunityfinder-a-framework-for-automated-causal-inference">OpportunityFinder panels</a></em> ship sample retail datasets ready for difference‑in‑differences.</p>
<p>When it comes to graph discovery methods, people tend to use classic datasets such as the 11‑node <em><a href="https://www.bnlearn.com/research/sachs05/">Sachs protein‑signaling map</a></em>, a real wet‑lab interventions dataset. Bayesian‑network classics like Asia and ALARM remain quick smoke tests. Pairwise direction algorithms rely on the <em><a href="https://webdav.tuebingen.mpg.de/cause-effect/">Tübingen cause–effect pairs</a></em>, and larger time‑series graphs come from gene‑regulation contests such as <em><a href="https://www.synapse.org/Synapse%3Asyn3049712">DREAM4</a></em>.</p>
<p>More recently we see <strong>language‑centric causal benchmarks</strong>. <em><a href="https://arxiv.org/abs/2312.04350">CLADDER</a></em> has 10k natural language questions across <a href="https://web.cs.ucla.edu/~kaoru/3-layer-causal-hierarchy.pdf">Pearl’s ladder</a>, while <em><a href="https://arxiv.org/abs/2502.08148">ACCESS</a></em> asks agents to build abstract causal graphs over multimodal vignettes before answering <em>why</em> queries.</p>
<p>As to multimodal causal inference, <a href="https://arxiv.org/abs/2506.09943">CausalVQA</a> is a benchmark for video question answering (VQA) that test models’ understanding of causality in the physical world.</p>
<hr>
</section>
<section id="challenges-and-mitigations" class="level2">
<h2 class="anchored" data-anchor-id="challenges-and-mitigations">Challenges and Mitigations</h2>
<p>Going beyond the happy path to production is often not a smooth ride. Here are some of common challenges in my experience:</p>
<section id="data-quality-and-the-missing-confounders" class="level3">
<h3 class="anchored" data-anchor-id="data-quality-and-the-missing-confounders">Data Quality and the Missing Confounders</h3>
<p>Observational datasets rarely contain every variable that shapes a treatment–outcome relationship, so even a state‑of‑the‑art estimator can inherit hidden bias.</p>
<p>To mitigate, insert a human‑review checkpoint right after the agent proposes its first causal graph: domain experts eyeball edges and nominate missing covariates. The software then launches automatic robustness probes such as placebo tests, synthetic confounder injections, and other refutation modules shipped with DoWhy, to quantify how fragile the estimate is. Crucially, if any refutation fails, the planner LLM must stop, annotate the failure, and either revise the graph or escalate to a human reviewer; surfacing a shaky result as “tentative” is better than silently proceeding. Some teams also run a “data‑profiling agent” that scans fresh tables for covariate drift or sparsity and warns the planner before analysis starts.</p>
</section>
<section id="hallucinations-and-overconfidence-in-planner-llms" class="level3">
<h3 class="anchored" data-anchor-id="hallucinations-and-overconfidence-in-planner-llms">Hallucinations and Over‑Confidence in Planner LLMs</h3>
<p>LLM planners are persuasive storytellers; a well phrased chain‑of‑thought can make a shaky causal graph feel ironclad.</p>
<p>Multi‑agent debate is a good recipe to reduce hallucination: a second LLM plays devil’s advocate, and challenges the assumptions that make an estimate causal:</p>
<ul>
<li><p>Placebo‑treatment test: replace the real treatment with a fake; any non‑zero effect flags hidden bias.</p></li>
<li><p>Synthetic‑confounder injection: add a random common cause and observe the ATE shift; big swings imply unmeasured confounding.</p></li>
<li><p>Overlap / positivity audit: verify that propensity scores span both arms; poor overlap triggers trimming or doubly robust methods.</p></li>
<li><p>Cross‑estimator consensus: pit a back‑door learner against an IV or front‑door estimator; disagreement above a threshold routes to human review.</p></li>
<li><p>Multi‑agent debate: affirmative and negative debaters contest every edge, a judge scores coherence.</p></li>
</ul>
<p>If any probe fails, the planner either tightens assumptions and reruns discovery or clearly labels the conclusion “inconclusive, additional data needed.” Final reports must surface the point estimate plus confidence intervals, sensitivity ranges, and a pass/fail tally for each refuter, so stakeholders see magnitude and robustness.</p>
</section>
<section id="modelselection-overfit-and-crossestimator-disagreement" class="level3">
<h3 class="anchored" data-anchor-id="modelselection-overfit-and-crossestimator-disagreement">Model‑Selection Over‑Fit and Cross‑Estimator Disagreement</h3>
<p>Auto‑tuning libraries can explore dozens of learners and hyper‑parameters, sometimes over‑fitting small causal datasets, especially with flexible models like causal forests. In this case, AutoML learns noise instead of real signal.</p>
<p>Mitigations include nested cross‑validation inside AutoCausality or causaltune, and parsimony priors that penalize needless complexity. If resource allows, the agent should run at least two conceptually different estimators, e.g., a back‑door regression and an instrumental‑variable model, and flag any large divergence in effect size as a red‑flag for human review.</p>
</section>
<section id="computation-cost-vs.-realtime-ambitions" class="level3">
<h3 class="anchored" data-anchor-id="computation-cost-vs.-realtime-ambitions">Computation&nbsp;Cost vs.&nbsp;Real‑Time Ambitions</h3>
<p>A planner–solver split can still burn thousands of tokens and heavy compute if the planner explores many what‑if branches.</p>
<p>Production dashboards cache discovery and refutation outputs keyed by a DAG hash; if the graph hasn’t changed, the agent re‑uses prior results. Another recipe is distilling a heavy LLM planner into a small fine‑tuned local model covers day‑to‑day traffic, while the costly cloud model handles weekly deep dives.</p>
</section>
<section id="privacy-and-governance" class="level3">
<h3 class="anchored" data-anchor-id="privacy-and-governance">Privacy and Governance</h3>
<p>Sensitive data such as medical records, customer logs usually cannot leave a private cluster.</p>
<p>Hybrid deployments solve this: an on‑prem LLM handles data‑aware steps, while a redacted summary (no PII) is sent to a cloud model for high‑level planning. All explanations pass through a redaction layer before logging, and every causal report carries an audit trail plus role‑based access controls.</p>
<hr>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Causal inference is transitioning from a highly specialized skill to a widely accessible capability. That’s not putting anyone out of a job. It is freeing us to ask better questions. A couple of years ago, answering “what actually drives our north star metric?” meant a quarter-long project. Today, it may be weeks or even days. That’s not just a productivity gain. It is a fundamental change in how we can think about our businesses.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/zzsi\.github\.io\/blog\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>